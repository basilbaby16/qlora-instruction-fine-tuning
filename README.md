# ğŸš€ QLoRA Instruction Fine-Tuning (PEFT)

This repository demonstrates **instruction fine-tuning of a Large Language Model (LLM)** using **QLoRA (Quantized Low-Rank Adaptation)** and **PEFT**, following modern best practices from Hugging Face.

The project is designed as a **portfolio-ready, end-to-end example**, starting from dataset preparation to training on GPU (Google Colab) and deployment-ready adapters.

---

## ğŸ“Œ Project Highlights

* âœ… Parameter-Efficient Fine-Tuning (PEFT)
* âœ… 4-bit quantization with **QLoRA** (memory efficient)
* âœ… Uses Hugging Face **transformers**, **peft**, **trl**, and **bitsandbytes**
* âœ… Training compatible with **Google Colab (T4 GPU)**
* âœ… Clean, modular Python project structure

---

## ğŸ§  What is QLoRA?

QLoRA allows fine-tuning very large models (7Bâ€“13B+) on consumer GPUs by:

* Loading the base model in **4-bit NF4 quantization**
* Freezing base weights
* Training only small **LoRA adapters**

This reduces memory usage from **~40GB â†’ ~8GB VRAM**.

---

## ğŸ—ï¸ Project Structure

```text
qlora-instruction-finetuning/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py              # Main training script
â”‚   â”œâ”€â”€ load_model.py         # Loads 4-bit quantized model
â”‚   â”œâ”€â”€ prepare_dataset.py    # Dataset loading & formatting
â”‚   â””â”€â”€ config.py             # Model & training config
â”‚
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ§© Base Model

You can use any open-source causal LLM supported by Hugging Face.

Recommended:

* `mistralai/Mistral-7B-Instruct-v0.2`
* `meta-llama/Meta-Llama-3-8B-Instruct` *(requires license acceptance)*

> âš ï¸ Training **must be done on GPU** (Google Colab / Kaggle / Cloud VM)

---

## ğŸ“¦ Installation (Google Colab)

```bash
pip install -r requirements.txt
```

If needed:

```bash
pip install bitsandbytes
```

---

## ğŸ” Hugging Face Authentication

Some models are gated and require authentication.

```python
from huggingface_hub import login
login()
```

Paste your Hugging Face access token when prompted.

---

## ğŸ“š Dataset Format

The dataset must be formatted as **instruction-style conversations**.

Example:

```text
<|system|>
You are a helpful assistant.
<|user|>
Summarize the following text...
<|assistant|>
Here is the summary...
```

The training script expects a column named:

```python
text
```

---

## ğŸ‹ï¸ Training

Run training with:

```bash
python src/train.py
```

Key training features:

* QLoRA (4-bit NF4)
* LoRA adapters (trainable parameters only)
* Optimized for low VRAM usage

---

## ğŸ’¾ Output

The training process saves:

* LoRA adapter weights
* Trainer checkpoints

These adapters can be:

* Re-loaded with the base model
* Pushed to Hugging Face Hub
* Used in inference or demos

---

## ğŸŒ Running on Google Colab

1. Push this repo to GitHub
2. Open Google Colab
3. Enable **GPU** (`Runtime â†’ Change runtime type`)
4. Clone repo:

```python
!git clone https://github.com/basilbaby16/qlora-instruction-finetuning.git
%cd qlora-instruction-finetuning
```

5. Install dependencies
6. Run training

---

## ğŸš€ Future Improvements

* [ ] Add Gradio demo
* [ ] Push adapters to Hugging Face Hub
* [ ] Experiment with different LoRA ranks
* [ ] Add evaluation metrics

---

## â­ Acknowledgements

* Hugging Face ğŸ¤—
* QLoRA paper by Dettmers et al.
* PEFT & TRL libraries

---

## ğŸ“œ License

This project is for **educational and research purposes**.
Model licenses follow their respective Hugging Face terms.
